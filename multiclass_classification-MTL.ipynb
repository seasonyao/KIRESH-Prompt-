{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 114,
     "referenced_widgets": [
      "7532a60d077248ca963f514988d41acc",
      "e39121739a4c4bffb16155e9a61a58cc",
      "ca0092edb8f5442a988c87c89930a10e",
      "5a975bc922a14c1b82245195b7c7f659",
      "f9dd503454b2450e957a96bff807c8d9",
      "222af74a298140ff9ec6e6f1f286a52b",
      "3516912b49bf4e3e98c9ce6c7b1b1469",
      "8335299626724853865234b86745e2a5",
      "fd6f40d5854c49f79056cebd16f86626",
      "cde06f09879848a3bfc5892390a51d36",
      "b13c341a69c14c059edc40e6b438ee80",
      "dd7699e7813d4b9f9e80990498a39539",
      "dd589fc95cd94cd190bc2640f9ef618c",
      "4641ff326eea446c88903e70b85c90d7",
      "c1db6876e9b04293b4077f13006b4a19",
      "b8728a6fcdc54b72a10c8bfdcf794fad"
     ]
    },
    "colab_type": "code",
    "id": "wuMlXT80GAMK",
    "outputId": "074dad6a-a18e-45bd-8c9c-29e318962dcd"
   },
   "outputs": [],
   "source": [
    "# Importing the libraries needed\n",
    "import pandas as pd\n",
    "import torch\n",
    "import transformers\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from transformers import AutoTokenizer, AutoModel\n",
    "import evaluate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "xQMKTZ4ARk12"
   },
   "outputs": [],
   "source": [
    "# Setting up the device for GPU usage\n",
    "\n",
    "from torch import cuda\n",
    "device = 'cuda' if cuda.is_available() else 'cpu'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'cuda'"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "global debug\n",
    "debug = {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TRAIN Dataset: (97, 4)\n",
      "TEST Dataset: (97, 4)\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "train_dataset = pd.read_csv(\"data/prompt_baseline_data/alcohol_train.csv\")\n",
    "test_dataset = pd.read_csv(\"data/prompt_baseline_data/alcohol_valid.csv\")\n",
    "\n",
    "train_dataset = train_dataset.iloc[:97]\n",
    "test_dataset = test_dataset.iloc[:97]\n",
    "\n",
    "print(\"TRAIN Dataset: {}\".format(train_dataset.shape))\n",
    "print(\"TEST Dataset: {}\".format(test_dataset.shape))\n",
    "\n",
    "OUT_DIM1=4\n",
    "OUT_DIM2=5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "JrBr2YesGdO_"
   },
   "outputs": [],
   "source": [
    "# Defining some key variables that will be used later on in the training\n",
    "MAX_LEN = 256\n",
    "TRAIN_BATCH_SIZE = 8\n",
    "VALID_BATCH_SIZE = 8\n",
    "EPOCHS = 1\n",
    "LEARNING_RATE = 1e-05\n",
    "\n",
    "MODEL_NAME = 'emilyalsentzer/Bio_ClinicalBERT'\n",
    "tokenizer = AutoTokenizer.from_pretrained(MODEL_NAME)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "2vX7kzaAHu39"
   },
   "outputs": [],
   "source": [
    "class Triage(Dataset):\n",
    "    def __init__(self, dataframe, tokenizer, max_len):\n",
    "        self.len = len(dataframe)\n",
    "        self.data = dataframe\n",
    "        self.tokenizer = tokenizer\n",
    "        self.max_len = max_len\n",
    "        \n",
    "    def __getitem__(self, index):\n",
    "        title = str(self.data.input[index])\n",
    "        title = \" \".join(title.split())\n",
    "        inputs = self.tokenizer.encode_plus(\n",
    "            title,\n",
    "            None,\n",
    "            add_special_tokens=True,\n",
    "            max_length=self.max_len,\n",
    "            padding='max_length',\n",
    "            return_token_type_ids=True,\n",
    "            truncation=True\n",
    "        )\n",
    "        ids = inputs['input_ids']\n",
    "        mask = inputs['attention_mask']\n",
    "\n",
    "        return {\n",
    "            'ids': torch.tensor(ids, dtype=torch.long),\n",
    "            'mask': torch.tensor(mask, dtype=torch.long),\n",
    "            'target1': torch.tensor(self.data.label1[index], dtype=torch.long),\n",
    "            'target2': torch.tensor(self.data.label2[index], dtype=torch.long)\n",
    "        } \n",
    "    \n",
    "    def __len__(self):\n",
    "        return self.len"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Zcwq13c0NE9c"
   },
   "outputs": [],
   "source": [
    "training_set = Triage(train_dataset, tokenizer, MAX_LEN)\n",
    "testing_set = Triage(test_dataset, tokenizer, MAX_LEN)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "l1BgA1CkQSYa"
   },
   "outputs": [],
   "source": [
    "train_params = {'batch_size': TRAIN_BATCH_SIZE,\n",
    "                'shuffle': True,\n",
    "                'num_workers': 0\n",
    "                }\n",
    "\n",
    "test_params = {'batch_size': VALID_BATCH_SIZE,\n",
    "                'shuffle': True,\n",
    "                'num_workers': 0\n",
    "                }\n",
    "\n",
    "training_loader = DataLoader(training_set, **train_params)\n",
    "testing_loader = DataLoader(testing_set, **test_params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating the customized model, by adding a drop out and a dense layer on top of distil bert to get the final output for the model. \n",
    "\n",
    "class ModelClass(torch.nn.Module):\n",
    "    def __init__(self):\n",
    "        super(ModelClass, self).__init__()\n",
    "        self.l1 = AutoModel.from_pretrained(MODEL_NAME)\n",
    "        \n",
    "        self.pre_classifier1 = torch.nn.Linear(768, 768)\n",
    "        self.dropout1 = torch.nn.Dropout(0.3)\n",
    "        self.classifier1 = torch.nn.Linear(768, OUT_DIM1)\n",
    "        \n",
    "        self.pre_classifier2 = torch.nn.Linear(768, 768)\n",
    "        self.dropout2 = torch.nn.Dropout(0.3)\n",
    "        self.classifier2 = torch.nn.Linear(768, OUT_DIM2)\n",
    "\n",
    "    def forward(self, input_ids, attention_mask):\n",
    "        output_1 = self.l1(input_ids=input_ids, attention_mask=attention_mask)\n",
    "        hidden_state = output_1[0]\n",
    "        \n",
    "        pooler1 = hidden_state[:, 0]\n",
    "        pooler1 = self.pre_classifier1(pooler1)\n",
    "        pooler1 = torch.nn.ReLU()(pooler1)\n",
    "        pooler1 = self.dropout1(pooler1)\n",
    "        output1 = self.classifier1(pooler1)\n",
    "        \n",
    "        pooler2 = hidden_state[:, 0]\n",
    "        pooler2 = self.pre_classifier2(pooler2)\n",
    "        pooler2 = torch.nn.ReLU()(pooler2)\n",
    "        pooler2 = self.dropout2(pooler2)\n",
    "        output2 = self.classifier2(pooler2)\n",
    "        \n",
    "        return output1, output2\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at emilyalsentzer/Bio_ClinicalBERT were not used when initializing BertModel: ['cls.predictions.transform.dense.bias', 'cls.predictions.bias', 'cls.seq_relationship.weight', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.decoder.weight', 'cls.predictions.transform.dense.weight', 'cls.seq_relationship.bias', 'cls.predictions.transform.LayerNorm.bias']\n",
      "- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "ModelClass(\n",
       "  (l1): BertModel(\n",
       "    (embeddings): BertEmbeddings(\n",
       "      (word_embeddings): Embedding(28996, 768, padding_idx=0)\n",
       "      (position_embeddings): Embedding(512, 768)\n",
       "      (token_type_embeddings): Embedding(2, 768)\n",
       "      (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "      (dropout): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (encoder): BertEncoder(\n",
       "      (layer): ModuleList(\n",
       "        (0): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (1): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (2): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (3): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (4): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (5): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (6): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (7): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (8): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (9): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (10): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (11): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (pooler): BertPooler(\n",
       "      (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "      (activation): Tanh()\n",
       "    )\n",
       "  )\n",
       "  (pre_classifier1): Linear(in_features=768, out_features=768, bias=True)\n",
       "  (dropout1): Dropout(p=0.3, inplace=False)\n",
       "  (classifier1): Linear(in_features=768, out_features=4, bias=True)\n",
       "  (pre_classifier2): Linear(in_features=768, out_features=768, bias=True)\n",
       "  (dropout2): Dropout(p=0.3, inplace=False)\n",
       "  (classifier2): Linear(in_features=768, out_features=5, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = ModelClass()\n",
    "model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating the loss function and optimizer\n",
    "loss_function = torch.nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.Adam(params =  model.parameters(), lr=LEARNING_RATE)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='section05'></a>\n",
    "### Fine Tuning the Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def valid(model, testing_loader):\n",
    "    model.eval()\n",
    "    tr_loss = 0\n",
    "    mcc1 = 0\n",
    "    macro_f1_1 = 0\n",
    "    micro_f1_1 = 0\n",
    "    mcc2 = 0\n",
    "    macro_f1_2 = 0\n",
    "    micro_f1_2 = 0\n",
    "    nb_tr_steps = 0\n",
    "    nb_tr_examples = 0\n",
    "    with torch.no_grad():\n",
    "        for _, data in enumerate(testing_loader, 0):\n",
    "            ids = data['ids'].to(device, dtype = torch.long)\n",
    "            mask = data['mask'].to(device, dtype = torch.long)\n",
    "            target1 = data['target1'].to(device, dtype = torch.long)\n",
    "            target2 = data['target2'].to(device, dtype = torch.long)\n",
    "            output1, output2 = model(ids, mask)\n",
    "            \n",
    "#             target1 = target1.squeeze()\n",
    "#             target2 = target2.squeeze()\n",
    "        \n",
    "#             output1 = output1.squeeze()\n",
    "#             output2 = output2.squeeze()\n",
    "            \n",
    "            loss1 = loss_function(output1, target1)\n",
    "            loss2 = loss_function(output2, target2)\n",
    "            loss = loss1+loss2\n",
    "            tr_loss += loss.item()\n",
    "            \n",
    "            big_val1, big_idx1 = torch.max(output1.data, dim=1)\n",
    "            big_val2, big_idx2 = torch.max(output2.data, dim=1)\n",
    "            \n",
    "            matthews_metric = evaluate.load(\"matthews_correlation\")\n",
    "            mcc_result1 = matthews_metric.compute(references=target1,\n",
    "                                              predictions=big_idx1)['matthews_correlation']\n",
    "            mcc_result2 = matthews_metric.compute(references=target2,\n",
    "                                              predictions=big_idx2)['matthews_correlation']\n",
    "\n",
    "            f1_metric = evaluate.load(\"f1\")\n",
    "            macro_f1_result1 = f1_metric.compute(predictions=big_idx1, references=target1, average='macro')['f1']\n",
    "            micro_f1_result1 = f1_metric.compute(predictions=big_idx1, references=target1, average='micro')['f1']\n",
    "            \n",
    "            macro_f1_result2 = f1_metric.compute(predictions=big_idx2, references=target2, average='macro')['f1']\n",
    "            micro_f1_result2 = f1_metric.compute(predictions=big_idx2, references=target2, average='micro')['f1']\n",
    "\n",
    "            mcc1 += mcc_result1\n",
    "            mcc2 += mcc_result2\n",
    "            macro_f1_1 += macro_f1_result1\n",
    "            macro_f1_2 += macro_f1_result2\n",
    "            micro_f1_1 += micro_f1_result1\n",
    "            micro_f1_2 += micro_f1_result2\n",
    "\n",
    "            nb_tr_steps += 1\n",
    "            nb_tr_examples+=target1.size(0)\n",
    "    \n",
    "    print(\"task1: presense\")\n",
    "    print(f'The Total MCC for Epoch {epoch}: {(mcc1*100)/nb_tr_steps}')\n",
    "    print(f'The Total macro_f1 for Epoch {epoch}: {(macro_f1_1*100)/nb_tr_steps}')\n",
    "    print(f'The Total micro_f1 for Epoch {epoch}: {(micro_f1_1*100)/nb_tr_steps}')\n",
    "    \n",
    "    print(\"task2: period\")\n",
    "    print(f'The Total MCC for Epoch {epoch}: {(mcc2*100)/nb_tr_steps}')\n",
    "    print(f'The Total macro_f1 for Epoch {epoch}: {(macro_f1_2*100)/nb_tr_steps}')\n",
    "    print(f'The Total micro_f1 for Epoch {epoch}: {(micro_f1_2*100)/nb_tr_steps}')\n",
    "    \n",
    "    epoch_loss = tr_loss/nb_tr_steps\n",
    "    print(f\"Validation Loss Epoch: {epoch_loss}\")\n",
    "    \n",
    "    return\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Defining the training function on the 80% of the dataset for tuning the distilbert model\n",
    "\n",
    "def train(epoch):\n",
    "    global debug\n",
    "    tr_loss = 0\n",
    "    mcc1 = 0\n",
    "    macro_f1_1 = 0\n",
    "    micro_f1_1 = 0\n",
    "    mcc2 = 0\n",
    "    macro_f1_2 = 0\n",
    "    micro_f1_2 = 0\n",
    "    nb_tr_steps = 0\n",
    "    nb_tr_examples = 0\n",
    "    model.train()\n",
    "    for _,data in enumerate(training_loader, 0):\n",
    "        ids = data['ids'].to(device, dtype = torch.long)\n",
    "        mask = data['mask'].to(device, dtype = torch.long)\n",
    "        target1 = data['target1'].to(device, dtype = torch.long)\n",
    "        target2 = data['target2'].to(device, dtype = torch.long)\n",
    "        output1, output2 = model(ids, mask)\n",
    "        \n",
    "        debug['target1'] = target1\n",
    "        debug['target2'] = target2\n",
    "        debug['output1'] = output1\n",
    "        debug['output2'] = output2\n",
    "        \n",
    "#         target1 = target1.squeeze()\n",
    "#         target2 = target2.squeeze()\n",
    "        \n",
    "#         output1 = output1.squeeze()\n",
    "#         output2 = output2.squeeze()\n",
    "\n",
    "        loss1 = loss_function(output1, target1)\n",
    "        loss2 = loss_function(output2, target2)\n",
    "        loss = loss1+loss2\n",
    "        tr_loss += loss.item()\n",
    "\n",
    "        big_val1, big_idx1 = torch.max(output1.data, dim=1)\n",
    "        big_val2, big_idx2 = torch.max(output2.data, dim=1)\n",
    "\n",
    "        matthews_metric = evaluate.load(\"matthews_correlation\")\n",
    "        mcc_result1 = matthews_metric.compute(references=target1,\n",
    "                                          predictions=big_idx1)['matthews_correlation']\n",
    "        mcc_result2 = matthews_metric.compute(references=target2,\n",
    "                                          predictions=big_idx2)['matthews_correlation']\n",
    "\n",
    "        f1_metric = evaluate.load(\"f1\")\n",
    "        macro_f1_result1 = f1_metric.compute(predictions=big_idx1, references=target1, average='macro')['f1']\n",
    "        micro_f1_result1 = f1_metric.compute(predictions=big_idx1, references=target1, average='micro')['f1']\n",
    "\n",
    "        macro_f1_result2 = f1_metric.compute(predictions=big_idx2, references=target2, average='macro')['f1']\n",
    "        micro_f1_result2 = f1_metric.compute(predictions=big_idx2, references=target2, average='micro')['f1']\n",
    "\n",
    "        mcc1 += mcc_result1\n",
    "        mcc2 += mcc_result2\n",
    "        macro_f1_1 += macro_f1_result1\n",
    "        macro_f1_2 += macro_f1_result2\n",
    "        micro_f1_1 += micro_f1_result1\n",
    "        micro_f1_2 += micro_f1_result2\n",
    "\n",
    "        nb_tr_steps += 1\n",
    "        nb_tr_examples+=target1.size(0)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        # # When using GPU\n",
    "        optimizer.step()\n",
    "\n",
    "    print(\"task1: presense\")\n",
    "    print(f'The Total MCC for Epoch {epoch}: {(mcc1*100)/nb_tr_steps}')\n",
    "    print(f'The Total macro_f1 for Epoch {epoch}: {(macro_f1_1*100)/nb_tr_steps}')\n",
    "    print(f'The Total micro_f1 for Epoch {epoch}: {(micro_f1_1*100)/nb_tr_steps}')\n",
    "    \n",
    "    print(\"task2: period\")\n",
    "    print(f'The Total MCC for Epoch {epoch}: {(mcc2*100)/nb_tr_steps}')\n",
    "    print(f'The Total macro_f1 for Epoch {epoch}: {(macro_f1_2*100)/nb_tr_steps}')\n",
    "    print(f'The Total micro_f1 for Epoch {epoch}: {(micro_f1_2*100)/nb_tr_steps}')\n",
    "    \n",
    "    epoch_loss = tr_loss/nb_tr_steps\n",
    "    print(f\"Training Loss Epoch: {epoch_loss}\")\n",
    "    \n",
    "    print('This is the validation section to print the accuracy and see how it performs')\n",
    "    print('Here we are leveraging on the dataloader crearted for the validation dataset, the approcah is using more of pytorch')\n",
    "\n",
    "    valid(model, testing_loader)\n",
    "    print('------------------------------------------------------------------')\n",
    "\n",
    "    return "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "task1: presense\n",
      "The Total MCC for Epoch 0: 3.889381488742141\n",
      "The Total macro_f1 for Epoch 0: 22.401263266647884\n",
      "The Total micro_f1 for Epoch 0: 32.69230769230769\n",
      "task2: period\n",
      "The Total MCC for Epoch 0: 4.015294067677567\n",
      "The Total macro_f1 for Epoch 0: 26.750571365955985\n",
      "The Total micro_f1 for Epoch 0: 40.38461538461539\n",
      "Training Loss Epoch: 2.862440586090088\n",
      "This is the validation section to print the accuracy and see how it performs\n",
      "Here we are leveraging on the dataloader crearted for the validation dataset, the approcah is using more of pytorch\n",
      "task1: presense\n",
      "The Total MCC for Epoch 0: -3.6491933878387277\n",
      "The Total macro_f1 for Epoch 0: 15.263070263070263\n",
      "The Total micro_f1 for Epoch 0: 22.115384615384617\n",
      "task2: period\n",
      "The Total MCC for Epoch 0: 6.3271582623203395\n",
      "The Total macro_f1 for Epoch 0: 14.253108003108004\n",
      "The Total micro_f1 for Epoch 0: 25.0\n",
      "Validation Loss Epoch: 2.8067535620469313\n",
      "------------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "for epoch in range(EPOCHS):\n",
    "    train(epoch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (<ipython-input-16-f0a3a850b68a>, line 2)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;36m  Cell \u001b[0;32mIn[16], line 2\u001b[0;36m\u001b[0m\n\u001b[0;31m    The Total MCC for Epoch 0: 7.039135250263674\u001b[0m\n\u001b[0m        ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "task1: presense\n",
    "The Total MCC for Epoch 0: 7.039135250263674\n",
    "The Total macro_f1 for Epoch 0: 28.80850630850631\n",
    "The Total micro_f1 for Epoch 0: 34.61538461538461\n",
    "task2: period\n",
    "The Total MCC for Epoch 0: 7.2460908384321625\n",
    "The Total macro_f1 for Epoch 0: 28.4947274947275\n",
    "The Total micro_f1 for Epoch 0: 37.5\n",
    "Training Loss Epoch: 2.9264204502105713\n",
    "This is the validation section to print the accuracy and see how it performs\n",
    "Here we are leveraging on the dataloader crearted for the validation dataset, the approcah is using more of pytorch\n",
    "task1: presense\n",
    "The Total MCC for Epoch 0: 3.774527286173485\n",
    "The Total macro_f1 for Epoch 0: 22.77093277093277\n",
    "The Total micro_f1 for Epoch 0: 30.76923076923077\n",
    "task2: period\n",
    "The Total MCC for Epoch 0: 9.494652962167164\n",
    "The Total macro_f1 for Epoch 0: 23.928340178340175\n",
    "The Total micro_f1 for Epoch 0: 36.53846153846154\n",
    "Validation Loss Epoch: 2.826401252012986\n",
    "------------------------------------------------------------------\n",
    "​\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "task1: presense\n",
    "The Total MCC for Epoch 0: 1.5186428224958337\n",
    "The Total macro_f1 for Epoch 0: 25.67104192104192\n",
    "The Total micro_f1 for Epoch 0: 33.65384615384615\n",
    "task2: period\n",
    "The Total MCC for Epoch 0: 9.016377922467722\n",
    "The Total macro_f1 for Epoch 0: 20.456117956117957\n",
    "The Total micro_f1 for Epoch 0: 32.69230769230769\n",
    "Training Loss Epoch: 2.9077738431783824\n",
    "This is the validation section to print the accuracy and see how it performs\n",
    "Here we are leveraging on the dataloader crearted for the validation dataset, the approcah is using more of pytorch\n",
    "task1: presense\n",
    "The Total MCC for Epoch 0: 7.367690333612365\n",
    "The Total macro_f1 for Epoch 0: 23.28856328856329\n",
    "The Total micro_f1 for Epoch 0: 31.73076923076923\n",
    "task2: period\n",
    "The Total MCC for Epoch 0: 5.777918830654928\n",
    "The Total macro_f1 for Epoch 0: 15.614524364524366\n",
    "The Total micro_f1 for Epoch 0: 26.923076923076923\n",
    "Validation Loss Epoch: 2.8747668266296387\n",
    "------------------------------------------------------------------"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "01_transformers_multiclass_classification.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.15"
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "222af74a298140ff9ec6e6f1f286a52b": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "3516912b49bf4e3e98c9ce6c7b1b1469": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "4641ff326eea446c88903e70b85c90d7": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "5a975bc922a14c1b82245195b7c7f659": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_8335299626724853865234b86745e2a5",
      "placeholder": "​",
      "style": "IPY_MODEL_3516912b49bf4e3e98c9ce6c7b1b1469",
      "value": " 442/442 [00:01&lt;00:00, 276B/s]"
     }
    },
    "7532a60d077248ca963f514988d41acc": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_ca0092edb8f5442a988c87c89930a10e",
       "IPY_MODEL_5a975bc922a14c1b82245195b7c7f659"
      ],
      "layout": "IPY_MODEL_e39121739a4c4bffb16155e9a61a58cc"
     }
    },
    "8335299626724853865234b86745e2a5": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "b13c341a69c14c059edc40e6b438ee80": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "IntProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "IntProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "Downloading: 100%",
      "description_tooltip": null,
      "layout": "IPY_MODEL_4641ff326eea446c88903e70b85c90d7",
      "max": 231508,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_dd589fc95cd94cd190bc2640f9ef618c",
      "value": 231508
     }
    },
    "b8728a6fcdc54b72a10c8bfdcf794fad": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "c1db6876e9b04293b4077f13006b4a19": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "ca0092edb8f5442a988c87c89930a10e": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "IntProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "IntProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "Downloading: 100%",
      "description_tooltip": null,
      "layout": "IPY_MODEL_222af74a298140ff9ec6e6f1f286a52b",
      "max": 442,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_f9dd503454b2450e957a96bff807c8d9",
      "value": 442
     }
    },
    "cde06f09879848a3bfc5892390a51d36": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "dd589fc95cd94cd190bc2640f9ef618c": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": "initial"
     }
    },
    "dd7699e7813d4b9f9e80990498a39539": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_b8728a6fcdc54b72a10c8bfdcf794fad",
      "placeholder": "​",
      "style": "IPY_MODEL_c1db6876e9b04293b4077f13006b4a19",
      "value": " 232k/232k [00:00&lt;00:00, 584kB/s]"
     }
    },
    "e39121739a4c4bffb16155e9a61a58cc": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "f9dd503454b2450e957a96bff807c8d9": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": "initial"
     }
    },
    "fd6f40d5854c49f79056cebd16f86626": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_b13c341a69c14c059edc40e6b438ee80",
       "IPY_MODEL_dd7699e7813d4b9f9e80990498a39539"
      ],
      "layout": "IPY_MODEL_cde06f09879848a3bfc5892390a51d36"
     }
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
